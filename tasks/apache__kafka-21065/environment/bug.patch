diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java b/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java
index 274c518489..c4f9c0f7f0 100644
--- a/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/internals/ProducerBatch.java
@@ -72,9 +72,6 @@ public final class ProducerBatch {
     private final AtomicInteger attempts = new AtomicInteger(0);
     private final boolean isSplitBatch;
     private final AtomicReference<FinalState> finalState = new AtomicReference<>(null);
-    private boolean bufferDeallocated = false;
-    // Tracks if the batch has been sent to the NetworkClient
-    private boolean inflight = false;
 
     int recordCount;
     int maxRecordSize;
@@ -584,22 +581,6 @@ public final class ProducerBatch {
         return reopened;
     }
 
-    public boolean isBufferDeallocated() {
-        return bufferDeallocated;
-    }
-
-    public void markBufferDeallocated() {
-        bufferDeallocated = true;
-    }
-
-    public boolean isInflight() {
-        return inflight;
-    }
-
-    public void setInflight(boolean inflight) {
-        this.inflight = inflight;
-    }
-
     // VisibleForTesting
     OptionalInt currentLeaderEpoch() {
         return currentLeaderEpoch;
diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java b/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java
index 757e00b2fc..d3c774cb6f 100644
--- a/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/internals/RecordAccumulator.java
@@ -1027,39 +1027,14 @@ public class RecordAccumulator {
     }
 
     /**
-     * Complete and deallocate the record batch
-     */
-    public void completeAndDeallocateBatch(ProducerBatch batch) {
-        completeBatch(batch);
-        deallocate(batch);
-    }
-
-    /**
-     * Only perform deallocation (and not removal from the incomplete set)
+     * Deallocate the record batch
      */
     public void deallocate(ProducerBatch batch) {
+        incomplete.remove(batch);
         // Only deallocate the batch if it is not a split batch because split batch are allocated outside the
         // buffer pool.
-        if (!batch.isSplitBatch()) {
-            if (batch.isBufferDeallocated()) {
-                log.warn("Skipping deallocating a batch that has already been deallocated. Batch is {}, created time is {}", batch, batch.createdMs);
-            } else {
-                batch.markBufferDeallocated();
-                if (batch.isInflight()) {
-                    // Create a fresh ByteBuffer to give to BufferPool to reuse since we can't safely call deallocate with the ProduceBatch's buffer
-                    free.deallocate(ByteBuffer.allocate(batch.initialCapacity()));
-                    throw new IllegalStateException("Attempting to deallocate a batch that is inflight. Batch is " + batch);
-                }
-                free.deallocate(batch.buffer(), batch.initialCapacity());
-            }
-        }
-    }
-
-    /**
-     * Remove from the incomplete list but do not free memory yet
-     */
-    public void completeBatch(ProducerBatch batch) {
-        incomplete.remove(batch);
+        if (!batch.isSplitBatch())
+            free.deallocate(batch.buffer(), batch.initialCapacity());
     }
 
     /**
@@ -1157,14 +1132,7 @@ public class RecordAccumulator {
                 dq.remove(batch);
             }
             batch.abort(reason);
-            if (batch.isInflight()) {
-                // KAFKA-19012: if the batch has been sent it might still be in use by the network client so we cannot allow it to be reused yet.
-                // We skip deallocating it now. When the request in network client completes with a response, either Sender.completeBatch() or
-                // Sender.failBatch() will be called with deallocateBatch=true. The buffer associated with the batch will be deallocated then.
-                completeBatch(batch);
-            } else {
-                completeAndDeallocateBatch(batch);
-            }
+            deallocate(batch);
         }
     }
 
@@ -1184,7 +1152,7 @@ public class RecordAccumulator {
             }
             if (aborted) {
                 batch.abort(reason);
-                completeAndDeallocateBatch(batch);
+                deallocate(batch);
             }
         }
     }
diff --git a/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java b/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java
index a30861d388..f9ac810ca1 100644
--- a/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java
+++ b/clients/src/main/java/org/apache/kafka/clients/producer/internals/Sender.java
@@ -171,12 +171,7 @@ public class Sender implements Runnable {
 
     private void maybeRemoveAndDeallocateBatch(ProducerBatch batch) {
         maybeRemoveFromInflightBatches(batch);
-        this.accumulator.completeAndDeallocateBatch(batch);
-    }
-
-    private void maybeRemoveAndDeallocateBatchLater(ProducerBatch batch) {
-        maybeRemoveFromInflightBatches(batch);
-        this.accumulator.completeBatch(batch);
+        this.accumulator.deallocate(batch);
     }
 
     /**
@@ -359,24 +354,6 @@ public class Sender implements Runnable {
         return false;
     }
 
-    private void failExpiredBatches(List<ProducerBatch> expiredBatches, long now, boolean deallocateBuffer) {
-        // Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics
-        // for expired batches. see the documentation of @TransactionState.resetIdempotentProducerId to understand why
-        // we need to reset the producer id here.
-        if (!expiredBatches.isEmpty())
-            log.trace("Expired {} batches in accumulator", expiredBatches.size());
-        for (ProducerBatch expiredBatch : expiredBatches) {
-            String errorMessage = "Expiring " + expiredBatch.recordCount + " record(s) for " + expiredBatch.topicPartition
-                + ":" + (now - expiredBatch.createdMs) + " ms has passed since batch creation. "
-                + "The request has not been sent, or no server response has been received yet.";
-            failBatch(expiredBatch, new TimeoutException(errorMessage), false, deallocateBuffer);
-            if (transactionManager != null && expiredBatch.inRetry()) {
-                // This ensures that no new batches are drained until the current in flight batches are fully resolved.
-                transactionManager.markSequenceUnresolved(expiredBatch);
-            }
-        }
-    }
-
     private long sendProducerData(long now) {
         MetadataSnapshot metadataSnapshot = metadata.fetchMetadataSnapshot();
         // get the list of partitions with data ready to send
@@ -428,10 +405,23 @@ public class Sender implements Runnable {
         accumulator.resetNextBatchExpiryTime();
         List<ProducerBatch> expiredInflightBatches = getExpiredInflightBatches(now);
         List<ProducerBatch> expiredBatches = this.accumulator.expiredBatches(now);
+        expiredBatches.addAll(expiredInflightBatches);
 
-        failExpiredBatches(expiredBatches, now, true);
-        failExpiredBatches(expiredInflightBatches, now, false);
-
+        // Reset the producer id if an expired batch has previously been sent to the broker. Also update the metrics
+        // for expired batches. see the documentation of @TransactionState.resetIdempotentProducerId to understand why
+        // we need to reset the producer id here.
+        if (!expiredBatches.isEmpty())
+            log.trace("Expired {} batches in accumulator", expiredBatches.size());
+        for (ProducerBatch expiredBatch : expiredBatches) {
+            String errorMessage = "Expiring " + expiredBatch.recordCount + " record(s) for " + expiredBatch.topicPartition
+                + ":" + (now - expiredBatch.createdMs) + " ms has passed since batch creation. " 
+                + "The request has not been sent, or no server response has been received yet.";
+            failBatch(expiredBatch, new TimeoutException(errorMessage), false);
+            if (transactionManager != null && expiredBatch.inRetry()) {
+                // This ensures that no new batches are drained until the current in flight batches are fully resolved.
+                transactionManager.markSequenceUnresolved(expiredBatch);
+            }
+        }
         sensors.updateProduceRequestMetrics(batches);
 
         // If we have any nodes that are ready to send + have sendable data, poll with 0 timeout so this can immediately
@@ -534,7 +524,6 @@ public class Sender implements Runnable {
         if (accumulator.hasIncomplete()) {
             log.error("Aborting producer batches due to fatal error", exception);
             accumulator.abortBatches(exception);
-            inFlightBatches.clear();
         }
     }
 
@@ -670,7 +659,6 @@ public class Sender implements Runnable {
      */
     private void completeBatch(ProducerBatch batch, ProduceResponse.PartitionResponse response, long correlationId,
                                long now, Map<TopicPartition, Metadata.LeaderIdAndEpoch> partitionsWithUpdatedLeaderInfo) {
-        batch.setInflight(false);
         Errors error = response.error;
 
         if (error == Errors.MESSAGE_TOO_LARGE && batch.recordCount > 1 && !batch.isDone() &&
@@ -708,7 +696,7 @@ public class Sender implements Runnable {
                 // tell the user the result of their request. We only adjust sequence numbers if the batch didn't exhaust
                 // its retries -- if it did, we don't know whether the sequence number was accepted or not, and
                 // thus it is not safe to reassign the sequence.
-                failBatch(batch, response, batch.attempts() < this.retries, true);
+                failBatch(batch, response, batch.attempts() < this.retries);
             }
             if (error.exception() instanceof InvalidMetadataException) {
                 if (error.exception() instanceof UnknownTopicOrPartitionException) {
@@ -761,16 +749,12 @@ public class Sender implements Runnable {
 
         if (batch.complete(response.baseOffset, response.logAppendTime)) {
             maybeRemoveAndDeallocateBatch(batch);
-        } else {
-            // Always safe to call deallocate because the batch keeps track of whether or not it was deallocated yet
-            this.accumulator.deallocate(batch);
         }
     }
 
     private void failBatch(ProducerBatch batch,
                            ProduceResponse.PartitionResponse response,
-                           boolean adjustSequenceNumbers,
-                           boolean deallocateBatch) {
+                           boolean adjustSequenceNumbers) {
         final RuntimeException topLevelException;
         if (response.error == Errors.TOPIC_AUTHORIZATION_FAILED)
             topLevelException = new TopicAuthorizationException(Collections.singleton(batch.topicPartition.topic()));
@@ -780,7 +764,7 @@ public class Sender implements Runnable {
             topLevelException = response.error.exception(response.errorMessage);
 
         if (response.recordErrors == null || response.recordErrors.isEmpty()) {
-            failBatch(batch, topLevelException, adjustSequenceNumbers, deallocateBatch);
+            failBatch(batch, topLevelException, adjustSequenceNumbers);
         } else {
             Map<Integer, RuntimeException> recordErrorMap = new HashMap<>(response.recordErrors.size());
             for (ProduceResponse.RecordError recordError : response.recordErrors) {
@@ -819,25 +803,23 @@ public class Sender implements Runnable {
                 }
             };
 
-            failBatch(batch, topLevelException, recordExceptions, adjustSequenceNumbers, deallocateBatch);
+            failBatch(batch, topLevelException, recordExceptions, adjustSequenceNumbers);
         }
     }
 
     private void failBatch(
         ProducerBatch batch,
         RuntimeException topLevelException,
-        boolean adjustSequenceNumbers,
-        boolean deallocateBatch
+        boolean adjustSequenceNumbers
     ) {
-        failBatch(batch, topLevelException, batchIndex -> topLevelException, adjustSequenceNumbers, deallocateBatch);
+        failBatch(batch, topLevelException, batchIndex -> topLevelException, adjustSequenceNumbers);
     }
 
     private void failBatch(
         ProducerBatch batch,
         RuntimeException topLevelException,
         Function<Integer, RuntimeException> recordExceptions,
-        boolean adjustSequenceNumbers,
-        boolean deallocateBatch
+        boolean adjustSequenceNumbers
     ) {
         this.sensors.recordErrors(batch.topicPartition.topic(), batch.recordCount);
 
@@ -851,20 +833,7 @@ public class Sender implements Runnable {
                     log.debug("Encountered error when transaction manager was handling a failed batch", e);
                 }
             }
-            if (deallocateBatch) {
-                maybeRemoveAndDeallocateBatch(batch);
-            } else {
-                // Fix for KAFKA-19012
-                // The pooled ByteBuffer associated with this batch might still be in use by the network client so we
-                // cannot allow it to be reused yet. We skip deallocating it now. When the request in the network client 
-                // completes with a response, either completeBatch() or failBatch() will be called with deallocateBatch=true.
-                // The buffer associated with the batch will be deallocated then.
-                maybeRemoveAndDeallocateBatchLater(batch);
-            }
-        } else {
-            if (deallocateBatch) {
-                this.accumulator.deallocate(batch);
-            }
+            maybeRemoveAndDeallocateBatch(batch);
         }
     }
 
@@ -917,7 +886,6 @@ public class Sender implements Runnable {
                     .setIndex(tp.partition())
                     .setRecords(records));
             recordsByPartition.put(tp, batch);
-            batch.setInflight(true);
         }
 
         String transactionalId = null;
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java
index 5d1fa387b9..d6ac75a37a 100644
--- a/clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/internals/RecordAccumulatorTest.java
@@ -405,7 +405,7 @@ public class RecordAccumulatorTest {
                 for (ProducerBatch batch : batches) {
                     for (@SuppressWarnings("UnusedLocalVariable") Record ignored : batch.records().records())
                         read++;
-                    accum.completeAndDeallocateBatch(batch);
+                    accum.deallocate(batch);
                 }
             }
         }
@@ -669,7 +669,7 @@ public class RecordAccumulatorTest {
 
         for (List<ProducerBatch> batches: results.values())
             for (ProducerBatch batch: batches)
-                accum.completeAndDeallocateBatch(batch);
+                accum.deallocate(batch);
 
         // should be complete with no unsent records.
         accum.awaitFlushCompletion();
@@ -1575,7 +1575,7 @@ public class RecordAccumulatorTest {
         assertEquals(1, batches.values().iterator().next().size());
         ProducerBatch batch = batches.values().iterator().next().get(0);
         int numSplitBatches = accum.splitAndReenqueue(batch);
-        accum.completeAndDeallocateBatch(batch);
+        accum.deallocate(batch);
 
         return numSplitBatches;
     }
@@ -1599,7 +1599,7 @@ public class RecordAccumulatorTest {
                     } else {
                         batch.complete(0L, 0L);
                     }
-                    accum.completeAndDeallocateBatch(batch);
+                    accum.deallocate(batch);
                 }
             }
         } while (batchDrained);
diff --git a/clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java b/clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java
index efd0a85d62..a7ff324961 100644
--- a/clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java
+++ b/clients/src/test/java/org/apache/kafka/clients/producer/internals/SenderTest.java
@@ -126,7 +126,6 @@ import static org.junit.jupiter.api.Assertions.assertFalse;
 import static org.junit.jupiter.api.Assertions.assertInstanceOf;
 import static org.junit.jupiter.api.Assertions.assertNotEquals;
 import static org.junit.jupiter.api.Assertions.assertNotNull;
-import static org.junit.jupiter.api.Assertions.assertNotSame;
 import static org.junit.jupiter.api.Assertions.assertNull;
 import static org.junit.jupiter.api.Assertions.assertSame;
 import static org.junit.jupiter.api.Assertions.assertThrows;
@@ -2184,10 +2183,7 @@ public class SenderTest {
     public void testCancelInFlightRequestAfterFatalError() throws Exception {
         final long producerId = 343434L;
         TransactionManager transactionManager = createTransactionManager();
-        long totalSize = 1024 * 1024;
-        String metricGrpName = "producer-custom-metrics";
-        MatchingBufferPool pool = new MatchingBufferPool(totalSize, batchSize, metrics, time, metricGrpName);
-        setupWithTransactionState(transactionManager, false, pool);
+        setupWithTransactionState(transactionManager);
 
         prepareAndReceiveInitProducerId(producerId, Errors.NONE);
         assertTrue(transactionManager.hasProducerId());
@@ -2199,8 +2195,6 @@ public class SenderTest {
         Future<RecordMetadata> future2 = appendToAccumulator(tp1);
         sender.runOnce();
 
-        assertFalse(pool.allMatch());
-
         client.respond(
             body -> body instanceof ProduceRequest && RequestTestUtils.hasIdempotentRecords((ProduceRequest) body),
             produceResponse(tp0, -1, Errors.CLUSTER_AUTHORIZATION_FAILED, 0));
@@ -2211,14 +2205,12 @@ public class SenderTest {
 
         sender.runOnce();
         assertFutureFailure(future2, ClusterAuthorizationException.class);
-        assertFalse(pool.allMatch(), "Batch should not be deallocated before the response is received");
 
         // Should be fine if the second response eventually returns
         client.respond(
             body -> body instanceof ProduceRequest && RequestTestUtils.hasIdempotentRecords((ProduceRequest) body),
             produceResponse(tp1, 0, Errors.NONE, 0));
         sender.runOnce();
-        assertTrue(pool.allMatch(), "The batch should have been de-allocated");
     }
 
     @Test
@@ -2444,15 +2436,12 @@ public class SenderTest {
             assertEquals(ApiKeys.PRODUCE, client.requests().peek().requestBuilder().apiKey());
             Node node = new Node(Integer.parseInt(id), "localhost", 0);
             assertEquals(1, client.inFlightRequestCount());
-            ProducerBatch inflightBatch = sender.inFlightBatches(tpId.topicPartition()).get(0);
-            assertTrue(inflightBatch.isInflight(), "Batch should be marked inflight after being sent");
             assertTrue(client.isReady(node, time.milliseconds()), "Client ready status should be true");
 
             Map<TopicIdPartition, ProduceResponse.PartitionResponse> responseMap = new HashMap<>();
             responseMap.put(tpId, new ProduceResponse.PartitionResponse(Errors.MESSAGE_TOO_LARGE));
             client.respond(new ProduceResponse(responseMap));
             sender.runOnce(); // split and reenqueue
-            assertFalse(inflightBatch.isInflight(), "Batch should be marked as not inflight after being split and re-enqueued");
             assertEquals(2, txnManager.sequenceNumber(tpId.topicPartition()), "The next sequence should be 2");
             // The compression ratio should have been improved once.
             assertEquals(CompressionType.GZIP.rate - CompressionRatioEstimator.COMPRESSION_RATIO_IMPROVING_STEP,
@@ -2510,16 +2499,14 @@ public class SenderTest {
         sender.runOnce();  // send request
         assertEquals(1, client.inFlightRequestCount());
         assertEquals(1, sender.inFlightBatches(tp0).size());
-        assertFalse(sender.inFlightBatches(tp0).get(0).isBufferDeallocated(), "Buffer not deallocated yet");
-        ProducerBatch inflightBatch = sender.inFlightBatches(tp0).get(0);
 
         time.sleep(REQUEST_TIMEOUT);
         assertFalse(pool.allMatch());
 
-        sender.runOnce();  // times out the request
+        sender.runOnce();  // expire the batch
         assertTrue(request1.isDone());
-        assertTrue(inflightBatch.isBufferDeallocated(), "Buffer should be deallocated after request timeout");
         assertTrue(pool.allMatch(), "The batch should have been de-allocated");
+        assertTrue(pool.allMatch());
 
         sender.runOnce();
         assertTrue(pool.allMatch(), "The batch should have been de-allocated");
@@ -3604,38 +3591,6 @@ public class SenderTest {
         }
     }
 
-    @Test
-    public void testNoBufferReuseWhenBatchExpires() throws Exception {
-        long totalSize = 1024 * 1024;
-        try (Metrics m = new Metrics()) {
-            BufferPool pool = new BufferPool(totalSize, batchSize, m, time, "producer-internal-metrics");
-
-            // Allocate and store a poolable buffer, then return it to the pool so the Sender can pick it up
-            ByteBuffer buffer = pool.allocate(batchSize, 0);
-            pool.deallocate(buffer);
-
-            setupWithTransactionState(null, false, pool);
-            appendToAccumulator(tp0, 0L, "key", "value");
-            sender.runOnce();  // connect
-            sender.runOnce();  // send produce request
-
-            assertEquals(1, client.inFlightRequestCount());
-            assertEquals(1, sender.inFlightBatches(tp0).size());
-
-            ProducerBatch batch = sender.inFlightBatches(tp0).get(0);
-            // Validate the backing array of the buffer is the same as the pooled one from the start
-            assertSame(buffer.array(), batch.records().buffer().array(), "Sender should have allocated the same buffer we created");
-
-            time.sleep(DELIVERY_TIMEOUT_MS + 100);
-            sender.runOnce();
-
-            ByteBuffer newBuffer = pool.allocate(batchSize, 0);
-
-            // TEST buffer should not be reused
-            assertNotSame(buffer.array(), newBuffer.array(), "Buffer should not be reused");
-        }
-    }
-
 
     private void verifyErrorMessage(ProduceResponse response, String expectedMessage) throws Exception {
         Future<RecordMetadata> future = appendToAccumulator(tp0, 0L, "key", "value");
