diff --git a/core/src/main/scala/kafka/server/metadata/BrokerMetadataPublisher.scala b/core/src/main/scala/kafka/server/metadata/BrokerMetadataPublisher.scala
index afc982aae0..35c44b9524 100644
--- a/core/src/main/scala/kafka/server/metadata/BrokerMetadataPublisher.scala
+++ b/core/src/main/scala/kafka/server/metadata/BrokerMetadataPublisher.scala
@@ -23,7 +23,6 @@ import kafka.log.LogManager
 import kafka.server.share.SharePartitionManager
 import kafka.server.{KafkaConfig, ReplicaManager}
 import kafka.utils.Logging
-import org.apache.kafka.common.TopicPartition
 import org.apache.kafka.common.errors.TimeoutException
 import org.apache.kafka.common.internals.Topic
 import org.apache.kafka.coordinator.group.GroupCoordinator
@@ -40,7 +39,6 @@ import org.apache.kafka.server.fault.FaultHandler
 import org.apache.kafka.storage.internals.log.{LogManager => JLogManager}
 
 import java.util.concurrent.CompletableFuture
-import scala.collection.mutable
 import scala.jdk.CollectionConverters._
 
 
@@ -186,22 +184,6 @@ class BrokerMetadataPublisher(
           case t: Throwable => metadataPublishingFaultHandler.handleFault("Error updating share " +
             s"coordinator with local changes in $deltaName", t)
         }
-        try {
-          // Notify the group coordinator about deleted topics.
-          val deletedTopicPartitions = new mutable.ArrayBuffer[TopicPartition]()
-          topicsDelta.deletedTopicIds().forEach { id =>
-            val topicImage = topicsDelta.image().getTopic(id)
-            topicImage.partitions().keySet().forEach {
-              id => deletedTopicPartitions += new TopicPartition(topicImage.name(), id)
-            }
-          }
-          if (deletedTopicPartitions.nonEmpty) {
-            groupCoordinator.onPartitionsDeleted(deletedTopicPartitions.asJava, RequestLocal.noCaching.bufferSupplier)
-          }
-        } catch {
-          case t: Throwable => metadataPublishingFaultHandler.handleFault("Error updating group " +
-            s"coordinator with deleted partitions in $deltaName", t)
-        }
         try {
           // Notify the share coordinator about deleted topics.
           val deletedTopicIds = topicsDelta.deletedTopicIds()
diff --git a/docs/streams/developer-guide/app-reset-tool.md b/docs/streams/developer-guide/app-reset-tool.md
index bc69cff10c..ea0dbede1b 100644
--- a/docs/streams/developer-guide/app-reset-tool.md
+++ b/docs/streams/developer-guide/app-reset-tool.md
@@ -56,7 +56,7 @@ Prerequisites
 
 # Step 1: Run the application reset tool
 
-If you are using **streams rebalance protocol** (available since AK 4.2), use the [Streams groups CLI](kafka-streams-group-sh#reset-offsets).
+If you are using **streams rebalance protocol** (available since AK 4.2), use the [Streams groups CLI](kafka-streams-group-sh.html#reset-offsets).
 
 If you are using **classic rebalance protocol** , run the classic application reset tool as described below.
 
diff --git a/docs/streams/developer-guide/kafka-streams-group-sh.md b/docs/streams/developer-guide/kafka-streams-group-sh.md
deleted file mode 100644
index d38a884f49..0000000000
--- a/docs/streams/developer-guide/kafka-streams-group-sh.md
+++ /dev/null
@@ -1,183 +0,0 @@
----
-title: Kafka Streams Groups Tool
-type: docs
-description: 
-weight: 14
-tags: ['kafka', 'docs']
-aliases: 
-keywords: 
----
-
-<!--
- Licensed to the Apache Software Foundation (ASF) under one or more
- contributor license agreements.  See the NOTICE file distributed with
- this work for additional information regarding copyright ownership.
- The ASF licenses this file to You under the Apache License, Version 2.0
- (the "License"); you may not use this file except in compliance with
- the License.  You may obtain a copy of the License at
-
-    http://www.apache.org/licenses/LICENSE-2.0
-
- Unless required by applicable law or agreed to in writing, software
- distributed under the License is distributed on an "AS IS" BASIS,
- WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- See the License for the specific language governing permissions and
- limitations under the License.
--->
-
-Use `kafka-streams-groups.sh` to manage **Streams groups** for the Streams Rebalance Protocol (KIP‑1071): list and describe groups, inspect members and offsets/lag, reset or delete offsets for input topics, and delete groups (optionally including internal topics).
-
-
-# Overview
-
-A **Streams group** is a broker‑coordinated group type for Kafka Streams that uses Streams‑specific RPCs and metadata, distinct from classic consumer groups. The CLI surfaces Streams‑specific states, assignments, and input‑topic offsets to simplify visibility and administration.
-
-**Use with care:** Mutating operations (offset resets/deletes, group deletion) affect how applications will reprocess data when restarted. Always preview with \--dry-run before executing and ensure application instances are stopped/inactive and the group is empty before executing the command. 
-
-# What the Streams Groups tool does
-
-  * **List Streams groups** across a cluster and display or filter by group state (Empty, Not Ready, Assigning, Reconciling, Stable, Dead).
-  * **Describe a Streams group** and show: 
-    * Group state, group epoch, target assignment epoch (with `--state`, `--verbose` for additional details).
-    * Per‑member info such as epochs, current vs target assignments, and whether a member still uses the classic protocol (with `--members` and `--verbose`).
-    * Input‑topic offsets and lag (with `--offsets`), to understand how far behind processing is.
-  * **Reset input‑topic offsets** for a Streams group to control reprocessing boundaries using precise specifiers (earliest, latest, to‑offset, to‑datetime, by‑duration, shift‑by, from‑file). Requires `--dry-run` or `--execute` and inactive instances.
-  * **Delete offsets** for input topics to force re‑consumption on next start.
-  * **Delete a Streams group** to clean up broker‑side Streams metadata (offsets, topology, assignments). Optionally delete all, or a subset of, **internal topics** at the same time using `--internal-topics`.
-
-
-
-# Usage
-
-The script is located in `bin/kafka-streams-groups.sh` and connects to your cluster via `--bootstrap-server`. For secured clusters, pass AdminClient properties using `--command-config`.
-    
-    
-    $ kafka-streams-groups.sh --bootstrap-server <host:port> [COMMAND] [OPTIONS]
-
-**Note:** `kafka-streams-groups.sh` complements the Streams Admin API for Streams groups. The CLI exposes list/describe/delete operations and offset management similar in spirit to consumer-group tools, but tailored to Streams groups defined in KIP‑1071. 
-
-# Commands
-
-## List Streams groups
-
-Discovering groups
-    
-    
-    # List all Streams groups
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 --list
-    
-
-## Describe Streams groups
-
-Inspecting group's state, members, and lag
-    
-    
-    # Describe a group: state + epochs
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --describe --group my-streams-app --state --verbose
-    
-    # Describe a group: members (assignments vs target, classic/streams)
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --describe --group my-streams-app --members --verbose
-    
-    # Describe a group: input-topic offsets and lag
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --describe --group my-streams-app --offsets
-    
-
-## Reset input-topic offsets (preview, then apply) {#reset-offsets}
-
-Ensure all application instances are stopped/inactive. Always preview changes with `--dry-run` before using `--execute`.
-    
-    
-    # Preview resetting all input topics to a specific timestamp
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --group my-streams-app \
-      --reset-offsets --all-input-topics --to-datetime 2025-01-31T23:57:00.000 \
-      --dry-run
-    
-    # Apply the reset
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --group my-streams-app \
-      --reset-offsets --all-input-topics --to-datetime 2025-01-31T23:57:00.000 \
-      --execute
-    
-
-## Delete offsets to force re-consumption
-
-Delete offsets for all or specific input topics to have the group re-read data on restart.
-    
-    
-    # Delete offsets for all input topics (execute)
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --group my-streams-app \
-      --delete-offsets --all-input-topics --execute
-    
-    # Delete offsets for specific topics
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --group my-streams-app \
-      --delete-offsets --topic input-a --topic input-b --execute
-    
-
-## Delete a Streams group (cleanup)
-
-Delete broker-side Streams metadata for a group and optionally remove a subset of internal topics.
-    
-    
-    # Delete Streams group metadata
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --delete --group my-streams-app
-    
-    # Delete a subset of internal topics alongside the group (use with care)
-    kafka-streams-groups.sh --bootstrap-server localhost:9092 \
-      --delete --group my-streams-app \
-      --internal-topics my-app-repartition-0,my-app-changelog
-    
-
-# All options and flags
-
-## Core actions
-
-  * `--list`: List Streams groups. Use `--state` to display/filter by state.
-  * `--describe`: Describe a group selected by `--group`. Combine with: 
-    * `--state` (group state and epochs), `--members` (members and assignments), `--offsets` (input and repartition topics offsets/lag).
-    * `--verbose` for additional details (e.g., leader epochs where applicable).
-  * `--reset-offsets`: Reset input-topic offsets (one group at a time; instances should be inactive). Choose exactly one specifier: 
-    * `--to-earliest`, `--to-latest`, `--to-current`, `--to-offset <n>`
-    * `--by-duration <PnDTnHnMnS>`, `--to-datetime <YYYY-MM-DDTHH:mm:SS.sss>`
-    * `--shift-by <n>` (±), `--from-file` (CSV)
-Scope: 
-    * `--all-input-topics` or one/more `--topic <name>`; some builds also support `--all-topics` (all input topics per broker topology metadata).
-Safety: 
-    * Requires `--dry-run` or `--execute`.
-  * `--delete-offsets`: Delete offsets for `--all-input-topics`, specific `--topic` names, or `--from-file`.
-  * `--delete`: Delete Streams group metadata; optionally pass `--internal-topics <list>` to delete a subset of internal topics.
-
-
-
-## Common flags
-
-  * `--group <id>`: Target Streams group (application.id).
-  * `--all-groups`: Operate on all groups (allowed with `--delete`).
-  * `--bootstrap-server <host:port>`: Broker(s) to connect to (required).
-  * `--command-config <file>`: Properties for AdminClient (security, timeouts, etc.).
-  * `--timeout <ms>`: Wait time for group stabilization in some operations (default: 5000ms).
-  * `--dry-run`, `--execute`: Preview vs apply for mutating operations.
-  * `--help`, `--version`, `--verbose`: Usage, version, verbosity.
-
-
-
-# Best practices and safety
-
-  * Preview changes with `--dry-run` to verify topic scope and impact before `--execute`.
-  * Use `--internal-topics` carefully: deleting internal topics removes state backing topics; only do this when you intend to rebuild state from input topics.
-
-
-
-This page documents `kafka-streams-groups.sh` capabilities for Streams groups as defined by KIP‑1071 and implemented in Apache Kafka.
-
-  * [Documentation](/documentation)
-  * [Kafka Streams](/documentation/streams)
-  * [Developer Guide](/documentation/streams/developer-guide/)
-
-
diff --git a/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinator.java b/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinator.java
index 753d1736f7..9eb6d1cfd3 100644
--- a/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinator.java
+++ b/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinator.java
@@ -64,7 +64,6 @@ import java.util.Optional;
 import java.util.OptionalInt;
 import java.util.Properties;
 import java.util.concurrent.CompletableFuture;
-import java.util.concurrent.ExecutionException;
 import java.util.function.IntSupplier;
 
 /**
@@ -410,17 +409,6 @@ public interface GroupCoordinator {
      */
     int partitionFor(String groupId);
 
-    /**
-     * Remove the provided deleted partitions offsets.
-     *
-     * @param topicPartitions   The deleted partitions.
-     * @param bufferSupplier    The buffer supplier tight to the request thread.
-     */
-    void onPartitionsDeleted(
-        List<TopicPartition> topicPartitions,
-        BufferSupplier bufferSupplier
-    ) throws ExecutionException, InterruptedException;
-
     /**
      * Group coordinator is now the leader for the given partition at the
      * given leader epoch. It should load cached state from the partition
diff --git a/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java b/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java
index 701e58f96c..f8dc5068db 100644
--- a/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java
+++ b/group-coordinator/src/main/java/org/apache/kafka/coordinator/group/GroupCoordinatorService.java
@@ -100,6 +100,7 @@ import org.apache.kafka.coordinator.group.metrics.GroupCoordinatorMetrics;
 import org.apache.kafka.coordinator.group.streams.StreamsGroupHeartbeatResult;
 import org.apache.kafka.image.MetadataDelta;
 import org.apache.kafka.image.MetadataImage;
+import org.apache.kafka.image.TopicsDelta;
 import org.apache.kafka.server.authorizer.AuthorizableRequestContext;
 import org.apache.kafka.server.authorizer.Authorizer;
 import org.apache.kafka.server.record.BrokerCompressionType;
@@ -136,7 +137,6 @@ import java.util.Properties;
 import java.util.Set;
 import java.util.concurrent.CompletableFuture;
 import java.util.concurrent.CompletionException;
-import java.util.concurrent.ExecutionException;
 import java.util.concurrent.Executors;
 import java.util.concurrent.atomic.AtomicBoolean;
 import java.util.function.IntSupplier;
@@ -2217,63 +2217,6 @@ public class GroupCoordinatorService implements GroupCoordinator {
         );
     }
 
-    /**
-     * See {@link GroupCoordinator#onPartitionsDeleted(List, BufferSupplier)}.
-     */
-    @Override
-    public void onPartitionsDeleted(
-        List<TopicPartition> topicPartitions,
-        BufferSupplier bufferSupplier
-    ) throws ExecutionException, InterruptedException {
-        throwIfNotActive();
-
-        var futures = new ArrayList<CompletableFuture<Void>>();
-
-        // Handle the partition deletion for committed offsets.
-        futures.addAll(
-            FutureUtils.mapExceptionally(
-                runtime.scheduleWriteAllOperation(
-                    "on-partition-deleted",
-                    Duration.ofMillis(config.offsetCommitTimeoutMs()),
-                    coordinator -> coordinator.onPartitionsDeleted(topicPartitions)
-                ),
-                exception -> {
-                    log.error("Could not delete offsets for deleted partitions {} due to: {}.",
-                        topicPartitions, exception.getMessage(), exception
-                    );
-                    return null;
-                }
-            )
-        );
-
-        // Handle the topic deletion for share state.
-        if (metadataImage != null) {
-            var topicIds = topicPartitions.stream()
-                .filter(tp -> metadataImage.topicMetadata(tp.topic()).isPresent())
-                .map(tp -> metadataImage.topicMetadata(tp.topic()).get().id())
-                .collect(Collectors.toSet());
-
-            if (!topicIds.isEmpty()) {
-                futures.addAll(
-                    FutureUtils.mapExceptionally(
-                        runtime.scheduleWriteAllOperation(
-                            "maybe-cleanup-share-group-state",
-                            Duration.ofMillis(config.offsetCommitTimeoutMs()),
-                            coordinator -> coordinator.maybeCleanupShareGroupState(topicIds)
-                        ),
-                        exception -> {
-                            log.error("Unable to cleanup state for the deleted topics {}", topicIds, exception);
-                            return null;
-                        }
-                    )
-                );
-            }
-        }
-
-        // Wait on the results.
-        CompletableFuture.allOf(futures.toArray(new CompletableFuture<?>[0]));
-    }
-
     /**
      * See {@link GroupCoordinator#onElection(int, int)}.
      */
@@ -2315,10 +2258,77 @@ public class GroupCoordinatorService implements GroupCoordinator {
         throwIfNotActive();
         Objects.requireNonNull(delta, "delta must be provided");
         Objects.requireNonNull(newImage, "newImage must be provided");
+
+        // Update the metadata image and propagate to runtime.
         var wrappedImage = new KRaftCoordinatorMetadataImage(newImage);
         var wrappedDelta = new KRaftCoordinatorMetadataDelta(delta);
         metadataImage = wrappedImage;
         runtime.onMetadataUpdate(wrappedDelta, wrappedImage);
+
+        // Handle partition deletions from the delta.
+        if (delta.topicsDelta() != null && !delta.topicsDelta().deletedTopicIds().isEmpty()) {
+            handlePartitionsDeletion(delta.topicsDelta());
+        }
+    }
+
+    /**
+     * Handles the deletion of topic partitions by scheduling write operations
+     * to delete committed offsets and clean up share group state.
+     *
+     * @param topicsDelta The topics delta containing deleted topic IDs.
+     */
+    private void handlePartitionsDeletion(TopicsDelta topicsDelta) {
+        var topicPartitions = new ArrayList<TopicPartition>();
+        var topicIds = topicsDelta.deletedTopicIds();
+
+        topicIds.forEach(topicId -> {
+            var topicImage = topicsDelta.image().getTopic(topicId);
+            if (topicImage != null) {
+                topicImage.partitions().keySet().forEach(partitionId ->
+                    topicPartitions.add(new TopicPartition(topicImage.name(), partitionId))
+                );
+            }
+        });
+
+        var futures = new ArrayList<CompletableFuture<Void>>();
+
+        if (!topicPartitions.isEmpty()) {
+            // Schedule offset deletion.
+            futures.addAll(
+                FutureUtils.mapExceptionally(
+                    runtime.scheduleWriteAllOperation(
+                        "on-partition-deleted",
+                        Duration.ofMillis(config.offsetCommitTimeoutMs()),
+                        coordinator -> coordinator.onPartitionsDeleted(topicPartitions)
+                    ),
+                    exception -> {
+                        log.error("Could not delete offsets for deleted partitions {} due to: {}.",
+                            topicPartitions, exception.getMessage(), exception);
+                        return null;
+                    }
+                )
+            );
+        }
+
+        if (!topicIds.isEmpty()) {
+            // Schedule share group state cleanup.
+            futures.addAll(
+                FutureUtils.mapExceptionally(
+                    runtime.scheduleWriteAllOperation(
+                        "maybe-cleanup-share-group-state",
+                        Duration.ofMillis(config.offsetCommitTimeoutMs()),
+                        coordinator -> coordinator.maybeCleanupShareGroupState(topicIds)
+                    ),
+                    exception -> {
+                        log.error("Unable to cleanup state for the deleted topics {}", topicIds, exception);
+                        return null;
+                    }
+                )
+            );
+        }
+
+        // Wait for all operations to complete.
+        CompletableFuture.allOf(futures.toArray(new CompletableFuture<?>[0])).join();
     }
 
     /**
